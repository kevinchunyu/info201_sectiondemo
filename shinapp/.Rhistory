library(glmnet)
x <- model.matrix(pscore_formula, data = data)[, -1]
y <- data$treat
set.seed(123)
cv_lasso <- cv.glmnet(x,y, alpha = 1)
cv_lasso$lambda.min
lasso_propensity <- glmnet(x = x, y = y, alpha = 1, lambda = cv_lasso$lambda.min)
x <- model.matrix(pscore_formula, data = data)[, -1]
y <- data$treat
set.seed(123)
cv_lasso <- cv.glmnet(x,y, alpha = 1)
print("best lambda value:", cv_lasso$lambda.min)
lasso_propensity <- glmnet(x = x, y = y, alpha = 1, lambda = cv_lasso$lambda.min)
x <- model.matrix(pscore_formula, data = data)[, -1]
y <- data$treat
set.seed(123)
cv_lasso <- cv.glmnet(x,y, alpha = 1)
paste("best lambda value:", cv_lasso$lambda.min)
lasso_propensity <- glmnet(x = x, y = y, alpha = 1, lambda = cv_lasso$lambda.min)
x <- model.matrix(pscore_formula, data = data)[, -1]
y <- data$treat
set.seed(123)
cv_lasso <- cv.glmnet(x,y, alpha = 1)
paste("best lambda value:", cv_lasso$lambda.min)
lasso_propensity <- glmnet(x = x, y = y, alpha = 1, lambda = cv_lasso$lambda.min)
lasso_propensity
x <- model.matrix(pscore_formula, data = data)[, -1]
y <- data$treat
set.seed(123)
cv_lasso <- cv.glmnet(x,y, alpha = 1)
paste("best lambda value:", cv_lasso$lambda.min)
lasso_propensity <- glmnet(x = x, y = y, alpha = 1, lambda = cv_lasso$lambda.min)
coef(lasso_propensity)
x <- model.matrix(pscore_formula, data = data)[, -1]
y <- data$treat
set.seed(123)
cv_lasso <- cv.glmnet(x,y, alpha = 1)
paste("best lambda value:", cv_lasso$lambda.min)
lasso_propensity <- glmnet(x = x, y = y, alpha = 1, lambda = cv_lasso$lambda.min)
data$agesq <- (data$age)^2
data$edusq <- (data$edu)^2
data$re74sq <- (data$re74)^2
data$re75sq <- (data$re75)^2
data$u74black <- (data$u74  * data$black)
pscore_formula <- as.formula(treat ~ age + agesq + edu + edusq + married +
nodegree + black + hisp + re74 + re75 + re74sq +
re75sq + u74black)
lpm_est <- lm(formula = pscore_formula, data = data)
summary(lpm_est)
p_score <- predict(lpm_est)
data <- data %>% mutate(p_hat = p_score)
head(data)
length(data$p_hat[data$p_hat < 0 | data$p_hat > 1])
x <- model.matrix(pscore_formula, data = data)[, -1]
y <- data$treat
set.seed(123)
cv_lasso <- cv.glmnet(x,y, alpha = 1)
paste("best lambda value:", cv_lasso$lambda.min)
lasso_propensity <- glmnet(x = x, y = y, alpha = 1, lambda = cv_lasso$lambda.min)
coef(lasso_propensity)
p_score <- predict(lpm_est)
data <- data %>% mutate(p_hat = p_score)
head(data)
length(data$p_hat[data$p_hat < 0 | data$p_hat > 1])
x <- model.matrix(pscore_formula, data = data)[, -1]
y <- data$treat
set.seed(123)
cv_lasso <- cv.glmnet(x,y, alpha = 1)
paste("best lambda value:", cv_lasso$lambda.min)
lasso_propensity <- glmnet(x = x, y = y, alpha = 1, lambda = cv_lasso$lambda.min)
coef(lasso_propensity)
glm(pscore_formula, family = binomial(), data = data)
mle_est <- glm(pscore_formula, family = binomial(), data = data)
mle_est <- glm(pscore_formula, family = binomial(), data = data)
mle_est
predict(mle_est, type = "response")
p_logit <- predict(mle_est, type = "response")
data % mutate(p_logit = p_logit)
data <- data %>%  mutate(p_logit = p_logit)
data <- data %>%mutate(p_logit = p_logit)
data <- data %>% mutate(p_logit = p_logit)
data <- data %>% mutate(p_logit = p_logit)
head(data)
source("~/.active-rstudio-document", echo=TRUE)
data
View
View(data)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
data_wa
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
data_19
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
data_17_20
View(data_17_20)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
data_17_20
# find park names used in the dataframe
park_names <- data_17_20 %>% select(ParkName)
park_names
unique(park_names)
# find park names used in the dataframe
park_names <- data_17_20 %>% select(unique(ParkName))
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
data_park
# Mutate and have location string "Parkname, Region, State". Example: "Mount Rainier, Pacific West, WA"
data_17_20_string <- data_wa %>% mutate(location_string = unite(ParkName, Region, State, sep=", "))
# Mutate and have location string "Parkname, Region, State". Example: "Mount Rainier, Pacific West, WA"
data_17_20_string <- data_wa %>% mutate(location_string = paste(ParkName, ", ", Region, ",", State)
# Mutate and have location string "Parkname, Region, State". Example: "Mount Rainier, Pacific West, WA"
data_17_20_string <- data_wa %>% mutate(location_string = paste(ParkName, ", ", Region, ",", State))
# find park names used in the dataframe
park_names <- data_17_20_string %>% select(ParkName)
data_17_20_string <- data_wa %>% mutate(location_string = paste(ParkName, ", ", Region, ",", State))
data_17_20_string
# Mutate and have location string "Parkname, Region, State". Example: "Mount Rainier, Pacific West, WA"
data_17_20_string <- data_wa %>% mutate(location_string = paste0(ParkName, ",", Region, ",", State))
data_17_20_string
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
data_park
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
data_park
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
data_wa_base_r <- data[data$State == "WA"]
data_wa_base_r <- data$State[data$State == "WA"]
data_wa_base_r
data_wa_base_r <- data[data$State == "WA",]
data_wa_base_r
data<- read.csv('https://raw.githubusercontent.com/kevinchunyu/info201_sectiondemo/main/data/countlove.csv')
# Creating a new column that divides articles with attendees using dplyr
mutate_df <- mutate(data, article_per_attendee = Total.Articles/Attendees)
# Creating a new column using built-in R
mutate_r <- data
mutate_r$art_per_attendee <- mutate_r$Total.Articles / mutate_r$Attendees
View(data)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
View(data)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
View(data_grouped)
?group_by
data_grouped <- data %>% group_by(State)
?group_by
data_grouped
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
data_grouped
data_grouped <- data %>% group_by(Region)
View(data_grouped)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
View(data_grouped)
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab5.R", echo=TRUE)
View(data_grouped)
# data frame 1
df1 = data.frame(CustomerId = c(1:6), Product = c("Oven","Television","Mobile","WashingMachine","Lightings","Ipad"))
df1
# data frame 2
df2 = data.frame(CustomerId = c(2, 4, 6, 7, 8), State = c("California","Newyork","Santiago","Texas","Indiana"))
df2
inner_join_df <-  merge(x=df1,y=df2,by="CustomerId")
inner_join_df
outer_join_df <- merge(x=df1, y=df2, by="CustomerId", all=TRUE)
outer_join_df
left_join_df <- merge(x=df1, y=df2, by="CustomerId", all.x=TRUE)
left_join_df
# RIGHT JOIN
right_join_df <- merge(x=df1, y=df2, by="CustomerId", all.y=TRUE)
right_join_df
source("~/.active-rstudio-document", echo=TRUE)
View(viewer_df)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
most_views_num
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/INFO201-TA-DEMO/a2-ans/code.R", echo=TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(glmnet)
data <- read.csv("nswpsid.csv")
data$agesq <- (data$age)^2
data$edusq <- (data$edu)^2
data$re74sq <- (data$re74)^2
data$re75sq <- (data$re75)^2
data$u74black <- (data$u74  * data$black)
pscore_formula <- as.formula(treat ~ age + agesq + edu + edusq + married +
nodegree + black + hisp + re74 + re75 + re74sq +
re75sq + u74black)
lpm_est <- lm(formula = pscore_formula, data = data)
p_score <- predict(lpm_est)
data <- data %>% mutate(p_hat = p_score)
mle_est <- glm(pscore_formula, family = binomial(), data = data)
p_logit <- predict(mle_est, type = "response")
data <- data %>% mutate(p_logit = p_logit)
head(data)
lower_bound <- max(min(data$p_logit[data$treat == 1]), min(data$p_logit[data$treat == 0]))
upper_bound <- min(max(data$p_logit[data$treat == 1]), max(data$p_logit[data$treat == 0]))
psid_trimmed <- data %>% filter(p_logit >= lower_bound & p_logit <= upper_bound)
head(psid_trimmed)
dropped_treated <- nrow(data[data$treat == 1, ]) - nrow(psid_trimmed[psid_trimmed$treat == 1, ])
dropped_control <- nrow(data[data$treat == 0, ]) - nrow(psid_trimmed[psid_trimmed$treat == 0, ])
paste("Number of treated dropped:", dropped_treated)
paste("Number of control dropeed:", dropped_control)
library(ggplot2)
ggplot(psid_trimmed[psid_trimmed$treat == 1, ], aes(x = p_logit , y = re78)) + geom_smooth(method = "loess", span = 0.5, method.args = list(degree =1)) + geom_point()
ggplot(psid_trimmed[psid_trimmed$treat == 0, ], aes(x = p_logit , y = re78)) + geom_smooth(method = "loess", span = 0.5, method.args = list(degree =1)) + geom_point()
# create new column strata using .bincode
psid_trimmed <- psid_trimmed %>% mutate(strata = .bincode(psid_trimmed$p_logit, c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1)))
summary_stats <- psid_trimmed %>% group_by(strata) %>% summarise(treated = sum(treat == 1), control = sum(treat == 0), total_units = n(), min_pscore = min(p_logit), max = max(p_logit))
summary_stats
pretreat_vars <- c('age', 'edu', 'black','hisp', 'married', 'nodegree', 're74',
're75', 'u74black')
rmcoll <- function(df, colnames = names(df)) {
df_ <- df[,colnames]
cc <- coef(lm(rep(1, nrow(df_)) ~ ., data = df_))
return (names(cc)[is.na(cc)])
}
for(stratum in 1: 10) {
# skip stratum 9
if(stratum != 9) {
print(paste("========= STRATA:", stratum, "========="))
stratum_df <- psid_trimmed[psid_trimmed$strata == stratum, ]
# identifies collinear variables & excludes from pretreat & add to sur_system
pretreat_vars <- pretreat_vars[! pretreat_vars %in% rmcoll(stratum_df)]
sur_system <- lapply(paste(pretreat_vars, '~treat'), as.formula)
sur_fit <- systemfit(sur_system, data = stratum_df, method = 'SUR')
null_system <- lapply(paste(pretreat_vars, '~1'), as.formula)
null_fit <- systemfit(null_system, data = stratum_df, method = 'SUR')
print(lrtest(null_fit, sur_fit))
}
}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(glmnet)
library(systemfit)
pretreat_vars <- c('age', 'edu', 'black','hisp', 'married', 'nodegree', 're74',
're75', 'u74black')
rmcoll <- function(df, colnames = names(df)) {
df_ <- df[,colnames]
cc <- coef(lm(rep(1, nrow(df_)) ~ ., data = df_))
return (names(cc)[is.na(cc)])
}
for(stratum in 1: 10) {
# skip stratum 9
if(stratum != 9) {
print(paste("========= STRATA:", stratum, "========="))
stratum_df <- psid_trimmed[psid_trimmed$strata == stratum, ]
# identifies collinear variables & excludes from pretreat & add to sur_system
pretreat_vars <- pretreat_vars[! pretreat_vars %in% rmcoll(stratum_df)]
sur_system <- lapply(paste(pretreat_vars, '~treat'), as.formula)
sur_fit <- systemfit(sur_system, data = stratum_df, method = 'SUR')
null_system <- lapply(paste(pretreat_vars, '~1'), as.formula)
null_fit <- systemfit(null_system, data = stratum_df, method = 'SUR')
print(lrtest(null_fit, sur_fit))
}
}
att <- 0
nt <- sum(summary_stats$treated)
for(stratum in 1:10) {
if(stratum != 9) {
nts <- summary_stats$treated[summary_stats$strata == stratum]
print(nts)
strata_df <- psid_trimmed[psid_trimmed$strata == stratum, ]
re78_st <- mean(strata_df$re78[strata_df$treat == 1])
re78_sc <- mean(strata_df$re78[strata_df$treat == 0])
att <- att + ((nts/nt)*(re78_st - re78_sc))
}
}
att
att <- 0
nt <- sum(summary_stats$treated) -13
for(stratum in 1:10) {
if(stratum != 9) {
nts <- summary_stats$treated[summary_stats$strata == stratum]
print(nts)
strata_df <- psid_trimmed[psid_trimmed$strata == stratum, ]
re78_st <- mean(strata_df$re78[strata_df$treat == 1])
re78_sc <- mean(strata_df$re78[strata_df$treat == 0])
att <- att + ((nts/nt)*(re78_st - re78_sc))
}
}
att
att <- 0
# 13 comes from strata 9 (where we have to exclude)
nt <- sum(summary_stats$treated) - 13
for(stratum in 1:10) {
if(stratum != 9) {
nts <- summary_stats$treated[summary_stats$strata == stratum]
strata_df <- psid_trimmed[psid_trimmed$strata == stratum, ]
re78_st <- mean(strata_df$re78[strata_df$treat == 1])
re78_sc <- mean(strata_df$re78[strata_df$treat == 0])
att <- att + ((nts/nt)*(re78_st - re78_sc))
}
}
paste("ATT:", att)
att <- 0
# 13 comes from strata 9 (where we have to exclude)
nt <- sum(summary_stats$treated) - 13
for(stratum in 1:10) {
if(stratum != 9) {
nts <- summary_stats$treated[summary_stats$strata == stratum]
strata_df <- psid_trimmed[psid_trimmed$strata == stratum, ]
re78_st <- weighted.mean(strata_df$re78[strata_df$treat == 1])
re78_sc <- weighted.mean(strata_df$re78[strata_df$treat == 0])
att <- att + ((nts/nt)*(re78_st - re78_sc))
}
}
paste("ATT:", att)
install.packages("Matching")
library(Matching)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(glmnet)
library(systemfit)
library(Matching)
# p_logits results
x <- data$p_logit
y <- data$re78
tr <- data$treat
rr <- Match(Y=Y, Tr=Tr, X=X, M=1, estimand = "ATT", CommonSupport = T)
# p_logits results
x <- data$p_logit
y <- data$re78
tr <- data$treat
rr <- Match(Y=y, Tr=tr, X=x, M=1, estimand = "ATT", CommonSupport = T)
summary(rr)
# p_logits results
x <- data$p_logit
y <- data$re78
tr <- data$treat
rr <- Match(Y=y, Tr=tr, X=x, M=1, estimand = "ATT", CommonSupport = T)
summary(rr)
lower_bound <- max(min(data$p_logit[data$treat == 1]), min(data$p_logit[data$treat == 0]))
upper_bound <- min(max(data$p_logit[data$treat == 1]), max(data$p_logit[data$treat == 0]))
psid_trimmed <- data %>% filter(p_logit >= lower_bound & p_logit <= upper_bound)
head(psid_trimmed)
dropped_treated <- nrow(data[data$treat == 1, ]) -
(psid_trimmed[psid_trimmed$treat == 1, ])
dropped_control <- nrow(data[data$treat == 0, ]) -
nrow(psid_trimmed[psid_trimmed$treat == 0, ])
paste("Number of treated dropped:", dropped_treated)
paste("Number of control dropeed:", dropped_control)
lower_bound <- max(min(data$p_logit[data$treat == 1]), min(data$p_logit[data$treat == 0]))
upper_bound <- min(max(data$p_logit[data$treat == 1]), max(data$p_logit[data$treat == 0]))
psid_trimmed <- data %>% filter(p_logit >= lower_bound & p_logit <= upper_bound)
head(psid_trimmed)
psid_1 <- psid_trimmed[psid_trimmed$treat == 1, ]
psid_0 <- psid_trimmed[psid_trimmed$treat == 0, ]
dropped_treated <- nrow(data[data$treat == 1, ]) - nrow(psid_1)
dropped_control <- nrow(data[data$treat == 0, ]) - nrow(psid_0)
paste("Number of treated dropped:", dropped_treated)
paste("Number of control dropeed:", dropped_control)
source("~/.active-rstudio-document", echo=TRUE)
cases_map
View(national)
View(states)
View(counties)
county_shapes
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab7.R", echo=TRUE)
#   )
# Step 6: Create the map
cases_map <- ggplot(map_data) +
geom_polygon(
mapping = aes(x = long, y = lat, group = group, fill = cases),
color="gray", size = 0.3
) +
coord_map() +
scale_fill_continuous(limits = c(0, max(map_data$cases)), na.value = "white", low="yellow", high="red") +
ggtitle("Covid cases of counties in Washington")
cases_map
blank_theme <- theme_bw() +
theme(
axis.line = element_blank(), # remove axis lines
axis.text = element_blank(), # remove axis labels
axis.ticks = element_blank(), # remove axis ticks
axis.title = element_blank(), # remove axis titles
plot.background = element_blank(), # remove gray background
panel.grid.major = element_blank(), # remove major grid lines
panel.grid.minor = element_blank(), # remove minor grid lines
panel.border = element_blank() # remove border around plot
)
# Step 6: Create the map
cases_map <- ggplot(map_data) +
geom_polygon(
mapping = aes(x = long, y = lat, group = group, fill = cases),
color="gray", size = 0.3
) +
coord_map() +
scale_fill_continuous(limits = c(0, max(map_data$cases)), na.value = "white", low="yellow", high="red") +
ggtitle("Covid cases of counties in Washington")
cases_map
# Step 6: Create the map
cases_map <- ggplot(map_data) +
geom_polygon(
mapping = aes(x = long, y = lat, group = group, fill = cases),
color="gray", size = 0.3
) +
blank_theme +
coord_map() +
scale_fill_continuous(limits = c(0, max(map_data$cases)), na.value = "white", low="yellow", high="red") +
ggtitle("Covid cases of counties in Washington")
cases_map
map_data("county")
View(map_data("county"))
polyname
View(county_shapes)
county
source("~/INFO201-TA-DEMO/info201_sectiondemo/winter2022/lab7.R", echo=TRUE)
states$date <- as.Date(states$date)
# Step 2: Get most recent counties data from dataset
counties_mod <- counties %>%
filter(date == max(date))
# Step 3: Use map_data function to join covid `counties` dataset with the map_data for county
#         (remember to filter for Washington)
## unite = polyname refers to the column name, region and sub region separated by a comma is as follows in line 36
county_shapes <- map_data("county") %>%
unite(polyname, region, subregion, sep = ",") %>%
left_join(counties.fips, by="polyname")
# Step 4: Merge map data and filtered covid data together
map_data <- county_shapes %>%
left_join(counties_mod, by="fips") %>%
filter(state == "Washington"& county != "Unknown")
# Step 5: Incorporate blank theme (essentially allows the map to be outputted nicely without
# #         any weird axes or other such "graph-things" in the way)
blank_theme <- theme_bw() +
theme(
axis.line = element_blank(), # remove axis lines
axis.text = element_blank(), # remove axis labels
axis.ticks = element_blank(), # remove axis ticks
axis.title = element_blank(), # remove axis titles
plot.background = element_blank(), # remove gray background
panel.grid.major = element_blank(), # remove major grid lines
panel.grid.minor = element_blank(), # remove minor grid lines
panel.border = element_blank() # remove border around plot
)
# Step 6: Create the map
cases_map <- ggplot(map_data) +
geom_polygon(
mapping = aes(x = long, y = lat, group = group, fill = cases),
color="gray", size = 0.3
) +
blank_theme +
coord_map() +
scale_fill_continuous(limits = c(0, max(map_data$cases)), na.value = "white", low="yellow", high="red") +
ggtitle("Covid cases of counties in Washington")
counties_mod <- counties %>%
filter(date == max(date))
# Step 3: Use map_data function to join covid `counties` dataset with the map_data for county
#         (remember to filter for Washington)
## unite = polyname refers to the column name, region and sub region separated by a comma is as follows in line 36
county_shapes <- map_data("county") %>%
unite(polyname, region, subregion, sep = ",") %>%
left_join(county.fips, by="polyname")
# Step 4: Merge map data and filtered covid data together
map_data <- county_shapes %>%
left_join(counties_mod, by="fips") %>%
filter(state == "Washington"& county != "Unknown")
# Step 5: Incorporate blank theme (essentially allows the map to be outputted nicely without
# #         any weird axes or other such "graph-things" in the way)
blank_theme <- theme_bw() +
theme(
axis.line = element_blank(), # remove axis lines
axis.text = element_blank(), # remove axis labels
axis.ticks = element_blank(), # remove axis ticks
axis.title = element_blank(), # remove axis titles
plot.background = element_blank(), # remove gray background
panel.grid.major = element_blank(), # remove major grid lines
panel.grid.minor = element_blank(), # remove minor grid lines
panel.border = element_blank() # remove border around plot
)
# Step 6: Create the map
cases_map <- ggplot(map_data) +
geom_polygon(
mapping = aes(x = long, y = lat, group = group, fill = cases),
color="gray", size = 0.3
) +
blank_theme +
coord_map() +
scale_fill_continuous(limits = c(0, max(map_data$cases)), na.value = "white", low="yellow", high="red") +
ggtitle("Covid cases of counties in Washington")
View(county)
View(county.fips )
install.packages("htmltools")
knitr::opts_chunk$set(echo = TRUE)
source("~/INFO201-TA-DEMO/student_help/student_indivhelp/exploratory-analysis-group-BB7/chart1.R", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
View(data)
source("~/.active-rstudio-document", echo=TRUE)
library(tidyverse)
data %>% groupby(type) %>% count(title)
data %>% group_by(type) %>% count(title)
data %>% group_by(type) %>% count()
data %>% group_by(country) %>% count()
source("~/repos/data-exploration-analysis/analysis.R", echo=TRUE)
shiny::runApp('INFO201-TA-DEMO/info201_sectiondemo/shinapp')
View(dat )
View(data)
runApp('INFO201-TA-DEMO/info201_sectiondemo/shinapp')
setwd("INFO201-TA-DEMO/info")
setwd("INFO201-TA-DEMO/info201_sectiondemo/shinapp/")
data <- read.csv("AMD.csv", stringsAsFactors = FALSE)
View(data)
data_volume <- data %>% select(Close, Volume) %>% rename("yval" = input$y_select)
# data wrangling depending on user input, preparing dataframe for graphing
data_volume <- data %>% select(Close, Volume) %>% rename("yval" = Close)
View(data_volume)
runApp()
